'''
Track one or more registered aruco markers, render their
orientation. Then publish the translation vector and rotation matrix
as a ros msg.
'''

import numpy as np
import cv2
import cv2.aruco as aruco
import glob
import extract_calibration # get existing calibration information

import rospy
from geometry_msgs.msg import Point

# setup ros node and publisher, for a point in space for now
rospy.init_node('quad_cam', anonymous=True)
point_pub = rospy.Publisher('cam_point', Point, queue_size = 10)

loop_rate = 30 # 30 frames per second
rate = rospy.Rate(loop_rate)

# initialize video capture
cap = cv2.VideoCapture(0)

# get existing calibration data for pose estimation
mtx = extract_calibration.camera_matrix
dist = extract_calibration.dist_matrix

def aruco_tracker():
    
    translation = [0, 0, 0]

    while not rospy.is_shutdown():
        ret, frame = cap.read()
        # operations on the frame come here
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        aruco_dict = aruco.Dictionary_get(aruco.DICT_4X4_50)
        parameters = aruco.DetectorParameters_create()

        #lists of ids and the corners beloning to each id
        corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)

        font = cv2.FONT_HERSHEY_SIMPLEX #font for displaying text (below)

        if np.all(ids != None):
            # Estimate pose of each marker and return the rotation and translation vectors
            # this is only going to detect one marker, we can pass a list of coners generated by detect markers
            # second parameter is the side length of the physical markers in meters
            # returns the rotation and translation vectors for each of the markers in corners[]
            rvec, tvec,_ = aruco.estimatePoseSingleMarkers(corners[0], 0.085, mtx, dist)

            # PRINT TRANSLATION VECTOR
            # not sure why these are nested twice but seems to be required for drawAxis
            translation = tvec[0][0]
            print(translation) # why is x never positive?

            # calculate the rotation matrix from the axis-angle rotation vector
            rmat, _ = cv2.Rodrigues(rvec)

            # PRINT ROTATION MATRIX
            print(rmat)
            print("\n")

            # do drawing on the camera frame
            aruco.drawAxis(frame, mtx, dist, rvec[0], tvec[0], 0.1) #Draw Axis
            aruco.drawDetectedMarkers(frame, corners) #Draw A square around the markers

            # draw the ID of the makers visible in the frame
            cv2.putText(frame, "Id: " + str(ids), (0,64), font, 1, (0,255,0),2,cv2.LINE_AA)

        # publish the translation vector points
        point_pub.publish( Point(translation[0], translation[1], translation[2]) )

        rate.sleep() # wait for the amount of time required to achieve the publish rate

        # Display the resulting frame
        cv2.imshow('frame',frame)
        # note the drawn axes are: X:red, Y:green, Z:blue
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # When everything done, release the capture
    cap.release()
    cv2.destroyAllWindows()



if __name__ == '__main__':
    try:
       aruco_tracker()
    except rospy.ROSInterruptException:
        pass