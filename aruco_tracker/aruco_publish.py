'''
Track one or more registered aruco markers, render their
orientation. Then publish the translation vector and rotation matrix
as a ros msg.
'''

import numpy as np
import cv2
import cv2.aruco as aruco
import glob
import extract_calibration # get existing calibration information

import rospy
import tf.transformations as tfs # for rotation matrix <> quaternions
import std_msgs.msg # for Header in the stamped point
from geometry_msgs.msg import Point, Quaternion, Pose, PoseStamped # stamped msgs include a header
from geometry_msgs.msg import PointStamped

# debug flags for output
DEBUG = True;

# setup ros node and publisher, for a point in space for now
rospy.init_node('quad_cam', anonymous=True)
pose_pub = rospy.Publisher('cam_pose', PoseStamped, queue_size = 10)

loop_rate = 30 # 30 frames per second
rate = rospy.Rate(loop_rate)

# initialize video capture
cap = cv2.VideoCapture(0)

# get existing calibration data for pose estimation
mtx = extract_calibration.camera_matrix
dist = extract_calibration.dist_matrix

def aruco_tracker():
    
    translation = [0, 0, 0]
    quats = [0, 0, 0, 0]

    while not rospy.is_shutdown():
        ret, frame = cap.read()
        # operations on the frame come here
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        aruco_dict = aruco.Dictionary_get(aruco.DICT_4X4_50)
        parameters = aruco.DetectorParameters_create()

        #lists of ids and the corners beloning to each id
        corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)

        font = cv2.FONT_HERSHEY_SIMPLEX #font for displaying text (below)

        if np.all(ids != None):
            # Estimate pose of each marker and return the rotation and translation vectors
            # this is only going to detect one marker, we can pass a list of coners generated by detect markers
            # second parameter is the side length of the physical markers in meters
            # returns the rotation and translation vectors for each of the markers in corners[]
            markerSideLength = 0.1524 # meters, 6 inches
            rvec, tvec, _ = aruco.estimatePoseSingleMarkers(corners[0], markerSideLength, mtx, dist)

            # notes on rvec, an axis-angle repesentation of the rotation
            # the direction of that vector indicates the axis of rotation
            # the length (norm) of the vector gives the angle of rotation about the prescribed axis
            axis_angle = rvec[0][0]

            direction = axis_angle
            angle = (sum(axis_angle))/3.0
            rot_mat = tfs.rotation_matrix(angle, direction)

            # PRINT TRANSLATION VECTOR
            # not sure why these are nested twice but seems to be required for drawAxis
            translation = tvec[0][0] # why is x never positive?

            # calculate the rotation matrix from the axis-angle rotation vector
            # rmat, _ = cv2.Rodrigues(rvec) # TODO: is this the correct rotation matrix or the tfs rot mtx
            # calculate quaternions form roation matrix
            quats = tfs.quaternion_from_matrix(rot_mat)

            if DEBUG:
                print("translation:\n") 
                print(translation)
                print("rotation matrix:\n")
                print(rot_mat)
                print("quaternions:\n")
                print(quats)

            # do drawing on the camera frame
            drawnAxisLength = 0.3048 # 12 inches as in a ruler
            aruco.drawAxis(frame, mtx, dist, rvec[0], tvec[0], drawnAxisLength) #Draw Axis
            aruco.drawDetectedMarkers(frame, corners) #Draw A square around the markers

            # draw the ID of the makers visible in the frame
            cv2.putText(frame, "Id: " + str(ids), (0,64), font, 1, (0,255,0),2,cv2.LINE_AA)

        # publish the stamped point
        p = Point(translation[0], translation[1], translation[2])
        q = Quaternion(quats[0], quats[1], quats[2], quats[3])
        pose = Pose(p, q)

        h = std_msgs.msg.Header()
        h.stamp = rospy.Time.now()
        h.frame_id = 'map'

        pose_pub.publish(h, pose)

        rate.sleep() # wait for the amount of time required to achieve the publish rate

        # Display the resulting frame
        cv2.imshow('frame',frame)
        # note the drawn axes are: X:red, Y:green, Z:blue
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # When everything done, release the capture
    cap.release()
    cv2.destroyAllWindows()



if __name__ == '__main__':
    try:
       aruco_tracker()
    except rospy.ROSInterruptException:
        pass